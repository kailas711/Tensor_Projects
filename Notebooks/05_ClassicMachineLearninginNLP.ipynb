{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b51a945",
   "metadata": {},
   "source": [
    "# Machine Learning for NLP\n",
    "\n",
    "\n",
    "Up to this point in the learning guide, only text preprocessing and embeddings have been discussed.  Remember that the output of the embedding step is a numeric vector that can now be used for machine learning. Once embeddings are generated, the next step is to select and train models according to the task at hand. Several factors go into the model selection process including:\n",
    "- Desired output / task \n",
    "- Volume of data \n",
    "- Computational resources available\n",
    "- Availability of labels \n",
    "- Data’s domain area \n",
    "- Training or serving latency requirements \n",
    "- Desired model complexity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a895010",
   "metadata": {},
   "source": [
    "## Classical Machine Learning in NLP\n",
    "\n",
    "Beginning with minimal complexity and gradually increasing complexing, traditional shallow machine learning algorithms can be used for an array of NLP tasks. Classification tasks are some of the more common tasks in NLP, including but not limited to text classification, named entity recognition (NER), and question answering are some.\n",
    "- **Text classification** refers to the set of tasks that involve assigning categories to text documents. A common example is an email filter labeling emails as spam or not spam. Since this output is binary, models like a logistic regression, support vector machine, or naive bayes can be applied to generate the classification. \n",
    "- **Named entity recognition** detects and classifies entities in text like people, places, etc. For example, NER is frequently used in healthcare to identify medical entities like diseases, drugs, and symptoms in patient records. Since NER is an instance of multi-class classification, algorithms like SVMs or naive bayes classifiers can be trained for NER tasks. Finally, another common NLP task that can leverage shallow algorithms is question answering. \n",
    "\n",
    "A model trained for **question answering** will assign probabilities to different answers depending on the question as input. Similar to NER, nearly any multiclass classification algorithm can be used for this task.  While not always the most complex approach, classical machine learning algorithms can cover a lot of ground in NLP, especially in the early stages of a project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abab8a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Read in spam filter example \n",
    "spam_df = pd.read_csv(r\"D:\\\\Coding_Stuff\\\\GitHub\\\\Natural-Language-Processing\\\\data\\\\emails.csv\")\n",
    "spam_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c031e6",
   "metadata": {},
   "source": [
    "Let's do some quick exploratory data analysis to identify any class imbalance. This will be important when evaluating the model down the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50bfb32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam\n",
       "0    4360\n",
       "1    1368\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_df[\"spam\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782241f9",
   "metadata": {},
   "source": [
    "From these `value_counts()`, it's clear that there is some imbalance between the distribution of our labels. Depending on the modeling technique, we may need to account for this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4f2cc97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b17594",
   "metadata": {},
   "source": [
    "Let's take a look at the average length of a spam and non-spam email. Since all text entries must be tokenized, we can write a function that tokenized the text by word and then apply it to the entire *pandas* `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7332a28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the `count_words` function\n",
    "def count_words(text):\n",
    "    words = word_tokenize(text)\n",
    "    return len(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95637e5b",
   "metadata": {},
   "source": [
    "Next, we'll apply the `count_work` function to count the number of words across our entire `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff888bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "      <th>counted_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam  counted_text\n",
       "0  Subject: naturally irresistible your corporate...     1           325\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1            90\n",
       "2  Subject: unbelievable new homes made easy  im ...     1            88"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply the `count_words` function the the entire DataFrame\n",
    "spam_df[\"counted_text\"] = spam_df[\"text\"].apply(count_words)\n",
    "spam_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea60d0aa",
   "metadata": {},
   "source": [
    "As a form of quick data analysis, let's take a look at the average length of an email, by label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f893f47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spam\n",
       "0    346.835321\n",
       "1    267.896199\n",
       "Name: counted_text, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average length of an email by label\n",
    "spam_df.groupby(\"spam\")[\"counted_text\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f367ecc2",
   "metadata": {},
   "source": [
    "Per the result above, it looks like there's a noteable different between the average email lenght of a spam email versus a non-spam email."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cc44ff",
   "metadata": {},
   "source": [
    "### Featurization \n",
    "\n",
    "Now that we've done a quick analysis of our data, we can get started with preparing the data for modeling:\n",
    "\n",
    "1. First, **stop words** are removed to ensure the remaining text carries meaning.\n",
    "2. Next, **Stemming** is applied to reduce words to their stems\n",
    "3. Lastly, **Continuous Bag of Words** algorithm is applied to generate embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15002a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecffade5",
   "metadata": {},
   "source": [
    "As mentioned in previous notebooks, we'll remove stop words from our corpus. Removing these stop words ensures that the model only uses words that carry meaning and context. For this example, we'll leverage the pre-loaded English stopwords from `NLTK`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43842529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to remove stop words\n",
    "def remove_stopwords(text: str) -> str:\n",
    "    no_punctuation = [character for character in text if character not in string.punctuation]\n",
    "    no_punctuation = \"\".join(no_punctuation)\n",
    "    \n",
    "    return \" \".join([word for word in no_punctuation.split() if word.lower() not in stopwords.words(\"english\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23e66e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the stopword removal function\n",
    "spam_df[\"removed_stopwords\"] = spam_df[\"text\"].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b32cd2",
   "metadata": {},
   "source": [
    "Verify stopword removal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c88e40c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "      <th>counted_text</th>\n",
       "      <th>removed_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "      <td>325</td>\n",
       "      <td>Subject naturally irresistible corporate ident...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>Subject stock trading gunslinger fanny merrill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>Subject unbelievable new homes made easy im wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>Subject 4 color printing special request addit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "      <td>Subject money get software cds software compat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam  counted_text  \\\n",
       "0  Subject: naturally irresistible your corporate...     1           325   \n",
       "1  Subject: the stock trading gunslinger  fanny i...     1            90   \n",
       "2  Subject: unbelievable new homes made easy  im ...     1            88   \n",
       "3  Subject: 4 color printing special  request add...     1            99   \n",
       "4  Subject: do not have money , get software cds ...     1            53   \n",
       "\n",
       "                                   removed_stopwords  \n",
       "0  Subject naturally irresistible corporate ident...  \n",
       "1  Subject stock trading gunslinger fanny merrill...  \n",
       "2  Subject unbelievable new homes made easy im wa...  \n",
       "3  Subject 4 color printing special request addit...  \n",
       "4  Subject money get software cds software compat...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cb98af",
   "metadata": {},
   "source": [
    "Now that stopwords have been removed, the next step is to apply `NLTKs` `PortStemmer` to reduce words to their stem. As a reminder, this reduction of a word to its stem allows for easier comparison of words and their respective meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5996764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25830c1",
   "metadata": {},
   "source": [
    "Define a stemming function we can apply to the entire `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db156c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stemming function\n",
    "def stem(text:str)-> str:\n",
    "    stemmer = PorterStemmer()\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2eea17",
   "metadata": {},
   "source": [
    "Apply the stemming function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d2a5f8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the stemming function \n",
    "spam_df[\"stemming\"] = spam_df[\"removed_stopwords\"].apply(stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a88b0f",
   "metadata": {},
   "source": [
    "Verify stemming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d62d4bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    subject natur irresist corpor ident lt realli ...\n",
       "1    subject stock trade gunsling fanni merril muzo...\n",
       "2    subject unbeliev new home made easi im want sh...\n",
       "3    subject 4 color print special request addit in...\n",
       "4    subject money get softwar cd softwar compat gr...\n",
       "Name: stemming, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_df[\"stemming\"][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47148b1",
   "metadata": {},
   "source": [
    "Now that the corpus has been pre-processed, the last step is to apply the `CountVectorizer` that will map our text to numeric values. With this conversion, we'll be able to apply various machine learning algorithms. Per the `sklearn` documentation, here's a quick summary of the `CountVectorizer` module:\n",
    "\n",
    "```Convert a collection of text documents to a matrix of token counts.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "313dbf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ce10e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantite, fit, and transform the `CountVectorizer`\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "vectorized_matrix = vectorizer.fit_transform(spam_df[\"stemming\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923bbdd7",
   "metadata": {},
   "source": [
    "Checking in on data types, note that the `CountVectorizer` returns a `scipy.sparse._csr.csr_matrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49ee5121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vectorized_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a960ea",
   "metadata": {},
   "source": [
    "### Modeling \n",
    "\n",
    "Now that the data has been pre-processed, let's split the data and fit a model. Before fitting a model, like any other machine learing problem, the data needs to be split into a training set and a test set. As a reminder, this split ensures that our model doesn't **overfit** our data and is generalizable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89c08318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectorized_matrix, spam_df[\"spam\"], test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e85983",
   "metadata": {},
   "source": [
    "For this example, we'll be leveraging a `Naive Bayes Classifier`. This classifier is one of the simplier classifiers. It's considered *generative* since it models the distribution of inputs for a given class or category. The model operates under the assumption that the features of the input data are conditionally independent given the class. This assumption allows the model to make predictions both quickly and accurately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de19b215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and train a Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "bayes = MultinomialNB()\n",
    "bayes.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b3ea4a",
   "metadata": {},
   "source": [
    "### Generate Predictions and Evaluate the Model\n",
    "\n",
    "Evaluation of these trained models is somewhat similar to any other classification task, however there are some nuances. In general, evaluation metrics are categorized into either **intrinsic evaluation** or **extrinsic evaluation**, where intrinsic refers to the performance of a component on a defined subtask and extrinsic refers to performance of the final objective.  Extrinsic evaluation is mostly specific to the task and business context, whereas metrics like **accuracy**, **precision** and **recall**, and **F1** are considered intrinsic. Beyond traditional metrics for classification models, there are a handful of NLP specific metrics that can be helpful. **Bilingual Evaluation Understudy (BLUE)**, **METEOR**, and **ROUGE** are all metrics that evaluate the quality of text that has been translated from one language to another. These can be useful for text generation, paraphrase generation, and text summarization. **Perplexity** is another probabilistic measure that can evaluate how “confused” the model is. It measures the randomness by calculating how strong the model is at guessing the next word in a sentence. While NLP evaluation metrics often have strong overlap with classification evaluation metrics, there are a handful of NLP specific intrinsic evaluation measures that can be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da848a6c",
   "metadata": {},
   "source": [
    "In the context of this model, we can leverage `sklearn`'s `classification_report` to quickly calculate several metrics at once, including `precision`, `recall`, `f1-score`, and `support`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "315fcc27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      1282\n",
      "           1       0.98      1.00      0.99       437\n",
      "\n",
      "    accuracy                           0.99      1719\n",
      "   macro avg       0.99      0.99      0.99      1719\n",
      "weighted avg       0.99      0.99      0.99      1719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "preds = bayes.predict(X_test)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a34f780",
   "metadata": {},
   "source": [
    "In addition to calculating metrics, in the case of classification generating a *confusion matrix* can be helpful in visualizing how the true labels and predictions are distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025e52b3",
   "metadata": {},
   "source": [
    "That's it! We've now successfully built a `Naive Bayes Classifier` on some e-mail text data! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
